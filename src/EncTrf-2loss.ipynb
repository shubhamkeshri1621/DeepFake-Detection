{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from facenet_pytorch import fixed_image_standardization\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import get_loader, read_dataset, CompositeDataset\n",
    "from model import FaceRecognitionCNN\n",
    "from utils import write_json, copy_file, count_parameters\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    return torch.index_select(a, dim, order_index.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder2DTransformer(nn.Module):\n",
    "    def __init__(self, face_recognition_cnn_path=None):\n",
    "        super(Encoder2DTransformer, self).__init__()\n",
    "\n",
    "        face_cnn = FaceRecognitionCNN()\n",
    "        \n",
    "        if face_recognition_cnn_path is not None:\n",
    "            face_cnn = nn.DataParallel(face_cnn)\n",
    "            state_dict = torch.load(face_recognition_cnn_path, map_location='cpu')\n",
    "            face_cnn.load_state_dict(state_dict)\n",
    "\n",
    "        if face_recognition_cnn_path:\n",
    "            modules = list(face_cnn.module.resnet.children())[:-4]\n",
    "            self.encoder2d = nn.Sequential(*modules)\n",
    "            modules = list(face_cnn.module.resnet.children())[-4:-1]\n",
    "            self.disc1 = nn.Sequential(*[Flatten(), *modules])\n",
    "            self.disc2 = face_cnn.module.relu\n",
    "            self.disc3 = face_cnn.module.dropout\n",
    "            self.disc4 = nn.Linear(512, 1)\n",
    "\n",
    "        else:\n",
    "            modules = list(face_cnn.resnet.children())[:-4]\n",
    "            self.encoder2d = nn.Sequential(*modules)\n",
    "            modules = list(face_cnn.resnet.children())[-4:-1]\n",
    "            self.disc1 = nn.Sequential(*[Flatten(), *modules])\n",
    "            self.disc2 = face_cnn.relu\n",
    "            self.disc3 = face_cnn.dropout\n",
    "            self.disc4 = nn.Linear(512, 1)\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=1792, nhead=4)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=4)\n",
    "        self.fc = nn.Linear(1792, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        batch_size, num_channels, depth, height, width = images.shape\n",
    "        images = images.permute(0, 2, 1, 3, 4)\n",
    "        images = images.reshape(batch_size * depth, num_channels, height, width)\n",
    "        out = self.encoder2d(images)\n",
    "        side = self.disc1(out)\n",
    "        side = self.disc2(side)\n",
    "        side = self.disc3(side)\n",
    "        side = self.disc4(side)\n",
    "        out = out.reshape(batch_size, depth, 1792, 1, 1)\n",
    "        out = out.squeeze(4)\n",
    "        out = out.squeeze(3)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = self.transformer_encoder(out)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = out.index_select(1, torch.tensor([0]).to(device))\n",
    "        out = out.squeeze()\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return  out, side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        np.float32,\n",
    "        transforms.ToTensor(),\n",
    "        fixed_image_standardization\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepfakes_faces_c23', 'original_faces_c23', 'face2face_faces_c23', 'neural_textures_faces_c23', 'faceswap_faces_c23']\n",
      "Using training data: \n",
      "deepfakes_faces_c23\n",
      "face2face_faces_c23\n",
      "faceswap_faces_c23\n",
      "neural_textures_faces_c23\n",
      "original_faces_c23\n"
     ]
    }
   ],
   "source": [
    "datasets = read_dataset(\n",
    "    '../dataset/mtcnn/', transform=transform,\n",
    "    max_images_per_video=11, max_videos=1000,\n",
    "    window_size=11, splits_path='../dataset/splits/'\n",
    ")\n",
    "# only neural textures c40 and original c40\n",
    "datasets = {\n",
    "    k: v for k, v in datasets.items() \n",
    "    if ('original' in k or 'neural' in k or 'face2face' in k or 'faceswap' in k or 'deepfakes' in k) and 'c23' in k\n",
    "}\n",
    "print('Using training data: ')\n",
    "print('\\n'.join(sorted(datasets.keys())))\n",
    "\n",
    "trains, vals, tests = [], [], []\n",
    "for data_dir_name, dataset in datasets.items():\n",
    "    train, val, test = dataset\n",
    "    # repeat original data multiple times to balance out training data\n",
    "    compression = data_dir_name.split('_')[-1]\n",
    "    num_tampered_with_same_compression = len({x for x in datasets.keys() if compression in x}) - 1\n",
    "    count = 1 if 'original' not in data_dir_name else num_tampered_with_same_compression\n",
    "    for _ in range(count):\n",
    "        trains.append(train)\n",
    "    vals.append(val)\n",
    "    tests.append(test)\n",
    "    \n",
    "train_dataset, val_dataset, test_dataset = CompositeDataset(*trains), CompositeDataset(*vals), CompositeDataset(*tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 63320, validation data size: 7675\n"
     ]
    }
   ],
   "source": [
    "tqdm.write('train data size: {}, validation data size: {}'.format(len(train_dataset), len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(\n",
    "    train_dataset, 64, shuffle=True, num_workers=2\n",
    ")\n",
    "val_loader = get_loader(\n",
    "    val_dataset, 64, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[device(type='cuda')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('training on', device)\n",
    "[device]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Encoder2DTransformer(\n",
       "    (encoder2d): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): BasicConv2d(\n",
       "        (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): BasicConv2d(\n",
       "        (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (6): BasicConv2d(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (3): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (4): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (8): Mixed_6a(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (9): Sequential(\n",
       "        (0): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (3): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (4): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (5): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (6): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (7): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (8): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (9): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (10): Mixed_7a(\n",
       "        (branch0): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (11): Sequential(\n",
       "        (0): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (3): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (4): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (12): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (13): AdaptiveAvgPool2d(output_size=1)\n",
       "    )\n",
       "    (disc1): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Dropout(p=0.6, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=512, bias=False)\n",
       "      (3): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (disc2): ReLU()\n",
       "    (disc3): Dropout(p=0.5, inplace=False)\n",
       "    (disc4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (encoder_layer): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "      (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "          (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "          (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "          (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "          (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=1792, out_features=5, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Encoder2DTransformer('./model/facenet/model.pt')\n",
    "#model = Encoder2DTransformer()\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "#if args.freeze_first_epoch:\n",
    "#for m in model.resnet.parameters():\n",
    "#    m.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape torch.Size([64, 3, 11, 160, 160])\n",
      "model params (trainable, total): (124508422, 124508422)\n"
     ]
    }
   ],
   "source": [
    "input_shape = next(iter(train_loader))[2].shape\n",
    "print('input shape', input_shape)\n",
    "# need to call this before summary!!!\n",
    "model.eval()\n",
    "# summary(model, input_shape[1:], batch_size=input_shape[0], device=device)\n",
    "print('model params (trainable, total):', count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight = torch.Tensor([0.8, 0.5, 0.5, 0.5, 0.5]).to(device)) \n",
    "criterion_side = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-5, weight_decay=1e-3\n",
    ")\n",
    "\n",
    "# decrease learning rate if validation accuracy has not increased\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=1/4, patience=2, verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_checkpoint(epoch, model, val_acc):\n",
    "    \n",
    "    model_dir = os.path.join('./model', 'enctrf2loss')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_path = os.path.join(model_dir, f'model.pt')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    model_info = {\n",
    "        'epoch': epoch,\n",
    "        'val_acc': val_acc[0],\n",
    "        'model_str': str(model)\n",
    "    }\n",
    "    json_path = os.path.join(model_dir, 'info.json')\n",
    "    write_json(model_info, json_path)\n",
    "\n",
    "    #src_model_file = os.path.join('facenet', 'model.py')\n",
    "    #dest_model_file = os.path.join(model_dir, 'model.py')\n",
    "    #copy_file(src_model_file, dest_model_file)\n",
    "\n",
    "    tqdm.write(f'New checkpoint saved at {model_path}')\n",
    "\n",
    "\n",
    "def print_training_info(batch_accuracy, loss, step):\n",
    "    log_info = 'Training - Loss: {:.4f}, Accuracy: {:.4f}'.format(loss.item(), batch_accuracy)\n",
    "    tqdm.write(log_info)\n",
    "\n",
    "    #writer.add_scalar('training loss', loss.item(), step)\n",
    "    #writer.add_scalar('training acc', batch_accuracy, step)\n",
    "\n",
    "\n",
    "def print_validation_info(criterion, device, model, val_loader, epoch, step):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_values = []\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        targets = []\n",
    "        outputs = []\n",
    "        for video_ids, frame_ids, images, target in val_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "            target = target.long()\n",
    "            output, _ = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            loss_values.append(loss.item())\n",
    "            targets.append(target)\n",
    "            outputs.append(output)\n",
    "            #predictions = outputs > 0.0\n",
    "            #all_predictions.append(predictions)\n",
    "            #all_targets.append(targets)\n",
    "            #if args.debug:\n",
    "            #    tqdm.write(outputs)\n",
    "            #    tqdm.write(predictions)\n",
    "            #    tqdm.write(targets)\n",
    "        \n",
    "        val_loss = sum(loss_values) / len(loss_values)\n",
    "        \n",
    "        outputs = torch.cat(outputs, 0)\n",
    "        targets = torch.cat(targets, 0)\n",
    "        \n",
    "        val_accuracy = float((outputs.argmax(1)).eq(targets).sum()) / len(targets)\n",
    "        \n",
    "        total_target = targets.unique(return_counts=True)[1]\n",
    "        pristine = ((outputs.argmax(1) == 0) * (targets == 0)).sum() / total_target[0]\n",
    "        face2face = ((outputs.argmax(1) == 1) * (targets == 1)).sum() / total_target[1]\n",
    "        faceswap = ((outputs.argmax(1) == 2) * (targets == 2)).sum() / total_target[2]\n",
    "        neural = ((outputs.argmax(1) == 3) * (targets == 3)).sum() / total_target[3]\n",
    "        deepfake = ((outputs.argmax(1) == 4) * (targets == 4)).sum() / total_target[4]\n",
    "        \n",
    "        tqdm.write(\n",
    "            'Validation - Loss: {:.3f}, Acc: {:.3f}, Pr: {:.3f}, Ff: {:.3f}, Fs: {:.3f}, Nt: {:.3f}, Df: {:.3f}'.format(\n",
    "                val_loss, val_accuracy, pristine, face2face, faceswap, neural, deepfake\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return val_accuracy, pristine, face2face, faceswap, neural, deepfake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  30%|       | 299/989 [04:22<09:17,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1163, Accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  30%|       | 299/989 [06:13<09:17,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.718, Acc: 0.791, Pr: 0.900, Ff: 0.787, Fs: 0.913, Nt: 0.504, Df: 0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  30%|       | 300/989 [06:21<6:59:15, 36.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  61%|    | 599/989 [10:30<05:58,  1.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0701, Accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  61%|    | 599/989 [12:17<05:58,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.713, Acc: 0.801, Pr: 0.823, Ff: 0.844, Fs: 0.786, Nt: 0.628, Df: 0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  61%|    | 600/989 [12:24<3:46:13, 34.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  91%| | 899/989 [16:32<01:11,  1.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1570, Accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  91%| | 899/989 [18:18<01:11,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.757, Acc: 0.814, Pr: 0.612, Ff: 0.873, Fs: 0.922, Nt: 0.738, Df: 0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  91%| | 900/989 [18:24<50:56, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0: 100%|| 989/989 [19:37<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.722, Acc: 0.813, Pr: 0.707, Ff: 0.924, Fs: 0.902, Nt: 0.629, Df: 0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  30%|       | 299/989 [04:28<10:21,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1134, Accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  30%|       | 299/989 [06:21<10:21,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.793, Acc: 0.821, Pr: 0.645, Ff: 0.846, Fs: 0.932, Nt: 0.759, Df: 0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  30%|       | 300/989 [06:27<7:01:58, 36.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  61%|    | 599/989 [10:49<05:37,  1.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0207, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  61%|    | 600/989 [12:39<3:40:16, 33.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.759, Acc: 0.816, Pr: 0.806, Ff: 0.886, Fs: 0.913, Nt: 0.525, Df: 0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  91%| | 899/989 [17:00<01:25,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0872, Accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  91%| | 899/989 [18:54<01:25,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.688, Acc: 0.833, Pr: 0.774, Ff: 0.839, Fs: 0.902, Nt: 0.740, Df: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  91%| | 900/989 [19:00<54:33, 36.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1: 100%|| 989/989 [20:14<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.815, Acc: 0.816, Pr: 0.711, Ff: 0.912, Fs: 0.862, Nt: 0.722, Df: 0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  30%|       | 299/989 [04:31<10:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0029, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  30%|       | 300/989 [06:20<6:25:28, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.762, Acc: 0.831, Pr: 0.717, Ff: 0.885, Fs: 0.932, Nt: 0.740, Df: 0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  61%|    | 599/989 [10:49<05:33,  1.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0100, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  61%|    | 599/989 [12:40<05:33,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.694, Acc: 0.843, Pr: 0.697, Ff: 0.846, Fs: 0.953, Nt: 0.808, Df: 0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  61%|    | 600/989 [12:46<3:55:27, 36.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  91%| | 899/989 [17:13<01:25,  1.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0723, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  91%| | 900/989 [19:00<48:50, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.709, Acc: 0.837, Pr: 0.713, Ff: 0.827, Fs: 0.953, Nt: 0.742, Df: 0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2: 100%|| 989/989 [20:19<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.855, Acc: 0.820, Pr: 0.675, Ff: 0.936, Fs: 0.966, Nt: 0.602, Df: 0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3:  30%|       | 299/989 [04:31<10:43,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0016, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3:  30%|       | 300/989 [06:24<6:37:31, 34.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.738, Acc: 0.842, Pr: 0.719, Ff: 0.917, Fs: 0.933, Nt: 0.717, Df: 0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3:  61%|    | 599/989 [10:49<05:49,  1.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0369, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3:  61%|    | 599/989 [12:40<05:49,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.693, Acc: 0.846, Pr: 0.757, Ff: 0.829, Fs: 0.942, Nt: 0.746, Df: 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3:  61%|    | 600/989 [12:46<3:53:44, 36.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3:  91%| | 899/989 [17:12<01:16,  1.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0758, Accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3:  91%| | 899/989 [19:06<01:16,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.671, Acc: 0.852, Pr: 0.775, Ff: 0.898, Fs: 0.959, Nt: 0.706, Df: 0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3:  91%| | 900/989 [19:12<54:50, 36.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 3: 100%|| 989/989 [20:29<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.838, Acc: 0.837, Pr: 0.729, Ff: 0.931, Fs: 0.927, Nt: 0.705, Df: 0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 4:  30%|       | 299/989 [04:22<09:21,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0077, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 4:  30%|       | 300/989 [06:16<6:42:24, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.755, Acc: 0.843, Pr: 0.725, Ff: 0.853, Fs: 0.934, Nt: 0.809, Df: 0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 4:  61%|    | 599/989 [10:33<05:08,  1.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0207, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 4:  61%|    | 600/989 [12:26<3:45:53, 34.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.792, Acc: 0.843, Pr: 0.702, Ff: 0.893, Fs: 0.957, Nt: 0.756, Df: 0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 4:  91%| | 899/989 [16:49<01:24,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0036, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 4:  91%| | 900/989 [18:43<51:38, 34.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.787, Acc: 0.839, Pr: 0.701, Ff: 0.883, Fs: 0.965, Nt: 0.786, Df: 0.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 4: 100%|| 989/989 [19:59<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.885, Acc: 0.820, Pr: 0.671, Ff: 0.946, Fs: 0.930, Nt: 0.647, Df: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 5:  30%|       | 299/989 [04:25<10:48,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0088, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 5:  30%|       | 300/989 [06:12<6:18:22, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.689, Acc: 0.846, Pr: 0.717, Ff: 0.883, Fs: 0.946, Nt: 0.739, Df: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 5:  61%|    | 599/989 [10:31<05:34,  1.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0017, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 5:  61%|    | 600/989 [12:22<3:40:20, 33.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.730, Acc: 0.845, Pr: 0.731, Ff: 0.888, Fs: 0.932, Nt: 0.761, Df: 0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 5:  91%| | 899/989 [16:42<01:25,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0029, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 5:  91%| | 900/989 [18:37<52:27, 35.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.903, Acc: 0.822, Pr: 0.641, Ff: 0.878, Fs: 0.946, Nt: 0.828, Df: 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 5: 100%|| 989/989 [19:54<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.761, Acc: 0.840, Pr: 0.714, Ff: 0.909, Fs: 0.945, Nt: 0.730, Df: 0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 6:  30%|       | 299/989 [04:36<11:23,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0373, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 6:  30%|       | 300/989 [06:28<6:37:48, 34.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.698, Acc: 0.841, Pr: 0.805, Ff: 0.871, Fs: 0.892, Nt: 0.682, Df: 0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 6:  61%|    | 599/989 [10:54<06:38,  1.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0048, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 6:  61%|    | 600/989 [12:50<3:51:41, 35.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.747, Acc: 0.848, Pr: 0.742, Ff: 0.915, Fs: 0.929, Nt: 0.749, Df: 0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 6:  91%| | 899/989 [17:20<01:18,  1.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0046, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 6:  91%| | 900/989 [19:09<50:02, 33.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.702, Acc: 0.851, Pr: 0.704, Ff: 0.886, Fs: 0.948, Nt: 0.772, Df: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 6: 100%|| 989/989 [20:28<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.748, Acc: 0.844, Pr: 0.680, Ff: 0.861, Fs: 0.934, Nt: 0.821, Df: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 7:  30%|       | 299/989 [04:37<09:58,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1144, Accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 7:  30%|       | 300/989 [06:27<6:30:44, 34.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.704, Acc: 0.847, Pr: 0.714, Ff: 0.906, Fs: 0.937, Nt: 0.748, Df: 0.930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 7:  61%|    | 599/989 [10:52<05:56,  1.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0011, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 7:  61%|    | 599/989 [12:43<05:56,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.686, Acc: 0.855, Pr: 0.711, Ff: 0.889, Fs: 0.966, Nt: 0.762, Df: 0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 7:  61%|    | 600/989 [12:50<3:55:35, 36.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 7:  91%| | 899/989 [17:05<01:15,  1.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0036, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 7:  91%| | 900/989 [19:03<53:22, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.662, Acc: 0.848, Pr: 0.761, Ff: 0.914, Fs: 0.905, Nt: 0.733, Df: 0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 7: 100%|| 989/989 [20:19<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.717, Acc: 0.838, Pr: 0.768, Ff: 0.710, Fs: 0.942, Nt: 0.834, Df: 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 8:  30%|       | 299/989 [04:28<11:13,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0032, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 8:  30%|       | 300/989 [06:11<6:07:04, 31.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.815, Acc: 0.847, Pr: 0.674, Ff: 0.863, Fs: 0.956, Nt: 0.864, Df: 0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 8:  61%|    | 599/989 [10:35<06:19,  1.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0009, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 8:  61%|    | 600/989 [12:20<3:29:29, 32.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.689, Acc: 0.854, Pr: 0.727, Ff: 0.863, Fs: 0.949, Nt: 0.804, Df: 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 8:  91%| | 899/989 [16:43<01:20,  1.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0017, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 8:  91%| | 899/989 [18:34<01:20,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.648, Acc: 0.860, Pr: 0.731, Ff: 0.884, Fs: 0.957, Nt: 0.796, Df: 0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 8:  91%| | 900/989 [18:41<53:54, 36.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf2loss/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 8: 100%|| 989/989 [19:58<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.650, Acc: 0.850, Pr: 0.787, Ff: 0.918, Fs: 0.942, Nt: 0.670, Df: 0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 9:  30%|       | 299/989 [04:23<10:10,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0012, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 9:  30%|       | 300/989 [06:15<6:34:48, 34.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.742, Acc: 0.849, Pr: 0.671, Ff: 0.913, Fs: 0.940, Nt: 0.800, Df: 0.920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 9:  61%|    | 599/989 [10:34<05:35,  1.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0040, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 9:  61%|    | 600/989 [12:26<3:43:18, 34.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.762, Acc: 0.834, Pr: 0.812, Ff: 0.885, Fs: 0.862, Nt: 0.704, Df: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 9:  91%| | 899/989 [16:52<01:13,  1.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0173, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 9:  91%| | 900/989 [18:45<51:28, 34.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.831, Acc: 0.836, Pr: 0.703, Ff: 0.922, Fs: 0.892, Nt: 0.780, Df: 0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 9: 100%|| 989/989 [20:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.672, Acc: 0.856, Pr: 0.758, Ff: 0.880, Fs: 0.927, Nt: 0.779, Df: 0.937\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "step = 1\n",
    "best_val_acc = 0.5\n",
    "for epoch in range(10):\n",
    "    for i, (video_ids, frame_ids, images, targets) in \\\n",
    "            tqdm(enumerate(train_loader), desc=f'training epoch {epoch}', total=len(train_loader)):\n",
    "        model.train()\n",
    "        # Set mini-batch dataset\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward, backward and optimize\n",
    "        outputs, sides = model(images)\n",
    "        targets = targets.long()\n",
    "        tiled_targets = tile(targets, 0, 11)\n",
    "        side_targets = (tiled_targets == 0).unsqueeze(1).float()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss_side = criterion_side(sides, side_targets)\n",
    "        model.zero_grad()\n",
    "        if i % 2 == 0:\n",
    "            loss.backward()\n",
    "        else:\n",
    "            loss_side.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_accuracy = float((outputs.argmax(1)).eq(targets).sum()) / len(targets)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Print log info\n",
    "        step += 1\n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            print_training_info(batch_accuracy, loss, step)\n",
    "\n",
    "        if (i + 1) % 300 == 0:\n",
    "            val_acc, pr_acc, ff_acc, fs_acc, nt_acc, df_acc = print_validation_info(\n",
    "                criterion, device, model, val_loader, epoch, step\n",
    "            )\n",
    "            if val_acc > best_val_acc:\n",
    "                save_model_checkpoint(epoch, model, (val_acc, pr_acc, ff_acc, fs_acc, nt_acc, df_acc))\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "    # validation step after full epoch\n",
    "    val_acc, pr_acc, ff_acc, fs_acc, nt_acc, df_acc = print_validation_info(\n",
    "        criterion, device, model, val_loader, epoch, step\n",
    "    )\n",
    "    lr_scheduler.step(val_acc)\n",
    "    if val_acc > best_val_acc:\n",
    "        save_model_checkpoint(epoch, model, (val_acc, pr_acc, ff_acc, fs_acc, nt_acc, df_acc))\n",
    "        best_val_acc = val_acc\n",
    "\n",
    "#    if epoch == 0:\n",
    "#        for m in model.resnet.parameters():\n",
    "#            m.requires_grad_(True)\n",
    "#        tqdm.write('Fine tuning on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 240/240 [01:42<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 1.068, Acc: 0.782, Pr: 0.878, Ff: 0.732, Fs: 0.828, Nt: 0.598, Df: 0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Encoder2DTransformer()\n",
    "model = nn.DataParallel(model)\n",
    "state_dict = torch.load('./model/enctrf2loss/model.pt', map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "test_loader = get_loader(\n",
    "    test_dataset, 32, shuffle=True, num_workers=2, drop_last=False\n",
    ")\n",
    "with torch.no_grad():\n",
    "    loss_values = []\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    for video_ids, frame_ids, images, target in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "        target = target.long()\n",
    "        output, _ = model(images)\n",
    "        targets.append(target)\n",
    "        outputs.append(output)\n",
    "        loss = criterion(output, target)\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "#                 predictions = outputs > 0.0\n",
    "#                 all_predictions.append(predictions)\n",
    "#                 all_targets.append(targets)\n",
    "\n",
    "    val_loss = sum(loss_values) / len(loss_values)\n",
    "\n",
    "    outputs = torch.cat(outputs, 0)\n",
    "    targets = torch.cat(targets, 0)\n",
    "        \n",
    "    val_accuracy = float((outputs.argmax(1)).eq(targets).sum()) / len(targets)\n",
    "\n",
    "    total_target = targets.unique(return_counts=True)[1]\n",
    "    pristine = ((outputs.argmax(1) == 0) * (targets == 0)).sum() / total_target[0]\n",
    "    face2face = ((outputs.argmax(1) == 1) * (targets == 1)).sum() / total_target[1]\n",
    "    faceswap = ((outputs.argmax(1) == 2) * (targets == 2)).sum() / total_target[2]\n",
    "    neural = ((outputs.argmax(1) == 3) * (targets == 3)).sum() / total_target[3]\n",
    "    deepfake = ((outputs.argmax(1) == 4) * (targets == 4)).sum() / total_target[4]\n",
    "    tqdm.write(\n",
    "        'Test - Loss: {:.3f}, Acc: {:.3f}, Pr: {:.3f}, Ff: {:.3f}, Fs: {:.3f}, Nt: {:.3f}, Df: {:.3f}'.format(\n",
    "            val_loss, val_accuracy, pristine, face2face, faceswap, neural, deepfake\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets.cpu().numpy(), outputs.cpu().argmax(1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9));\n",
    "ax = sns.heatmap(cm, xticklabels = ['Pr', 'Ff', 'Fs', 'Nt', 'Df'], yticklabels = ['Pr', 'Ff', 'Fs', 'Nt', 'Df'], annot = True);\n",
    "ax.set(xlabel = 'True', ylabel = 'Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
